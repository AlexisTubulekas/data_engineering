{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "grand-covering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continental-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.113:7077\") \\\n",
    "        .appName(\"alexistubulekasA3_partA\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .config(\"spark.cores.max\",2)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compact-stand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1862234"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A.1.1 Read the English transcripts with Spark, and count the number of lines.\n",
    "\n",
    "rdd_en = spark_context.newAPIHadoopFile(\n",
    "    'hdfs://192.168.2.113:9000/europarl/europarl-v7.sv-en.en',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text',\n",
    "    conf={'textinputformat.record.delimiter': '\\n'}\n",
    ")\\\n",
    ".cache() # Keep this RDD in memory!\n",
    "\n",
    "rdd_en.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "graduate-developer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1862234"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A.1.2 Do the same with the other language (so that you have a separate lineage of RDDs for each).\n",
    "rdd_sv = spark_context.newAPIHadoopFile(\n",
    "    'hdfs://192.168.2.113:9000/europarl/europarl-v7.sv-en.sv',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text',\n",
    "    conf={'textinputformat.record.delimiter': '\\n'}\n",
    ")\\\n",
    ".cache() # Keep this RDD in memory!\n",
    "rdd_sv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.1.3 Verify that the line counts are the same for the two languages.\n",
    "\n",
    "# Ans: Yes they are the same as seen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "third-digest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# A.1.4 Count the number of partitions.\n",
    "print(rdd_en.getNumPartitions())\n",
    "print(rdd_sv.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naked-press",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['resumption', 'of', 'the', 'session'], ['i', 'declare', 'resumed', 'the', 'session', 'of', 'the', 'european', 'parliament', 'adjourned', 'on', 'friday', '17', 'december', '1999,', 'and', 'i', 'would', 'like', 'once', 'again', 'to', 'wish', 'you', 'a', 'happy', 'new', 'year', 'in', 'the', 'hope', 'that', 'you', 'enjoyed', 'a', 'pleasant', 'festive', 'period.'], ['although,', 'as', 'you', 'will', 'have', 'seen,', 'the', 'dreaded', \"'millennium\", \"bug'\", 'failed', 'to', 'materialise,', 'still', 'the', 'people', 'in', 'a', 'number', 'of', 'countries', 'suffered', 'a', 'series', 'of', 'natural', 'disasters', 'that', 'truly', 'were', 'dreadful.'], ['you', 'have', 'requested', 'a', 'debate', 'on', 'this', 'subject', 'in', 'the', 'course', 'of', 'the', 'next', 'few', 'days,', 'during', 'this', 'part-session.'], ['in', 'the', 'meantime,', 'i', 'should', 'like', 'to', 'observe', 'a', \"minute'\", 's', 'silence,', 'as', 'a', 'number', 'of', 'members', 'have', 'requested,', 'on', 'behalf', 'of', 'all', 'the', 'victims', 'concerned,', 'particularly', 'those', 'of', 'the', 'terrible', 'storms,', 'in', 'the', 'various', 'countries', 'of', 'the', 'european', 'union.'], ['please', 'rise,', 'then,', 'for', 'this', \"minute'\", 's', 'silence.'], ['(the', 'house', 'rose', 'and', 'observed', 'a', \"minute'\", 's', 'silence)'], ['madam', 'president,', 'on', 'a', 'point', 'of', 'order.'], ['you', 'will', 'be', 'aware', 'from', 'the', 'press', 'and', 'television', 'that', 'there', 'have', 'been', 'a', 'number', 'of', 'bomb', 'explosions', 'and', 'killings', 'in', 'sri', 'lanka.'], ['one', 'of', 'the', 'people', 'assassinated', 'very', 'recently', 'in', 'sri', 'lanka', 'was', 'mr', 'kumar', 'ponnambalam,', 'who', 'had', 'visited', 'the', 'european', 'parliament', 'just', 'a', 'few', 'months', 'ago.']]\n",
      "[['återupptagande', 'av', 'sessionen'], ['jag', 'förklarar', 'europaparlamentets', 'session', 'återupptagen', 'efter', 'avbrottet', 'den', '17', 'december.', 'jag', 'vill', 'på', 'nytt', 'önska', 'er', 'ett', 'gott', 'nytt', 'år', 'och', 'jag', 'hoppas', 'att', 'ni', 'haft', 'en', 'trevlig', 'semester.'], ['som', 'ni', 'kunnat', 'konstatera', 'ägde', '\"den', 'stora', 'år', '2000-buggen\"', 'aldrig', 'rum.', 'däremot', 'har', 'invånarna', 'i', 'ett', 'antal', 'av', 'våra', 'medlemsländer', 'drabbats', 'av', 'naturkatastrofer', 'som', 'verkligen', 'varit', 'förskräckliga.'], ['ni', 'har', 'begärt', 'en', 'debatt', 'i', 'ämnet', 'under', 'sammanträdesperiodens', 'kommande', 'dagar.'], ['till', 'dess', 'vill', 'jag', 'att', 'vi,', 'som', 'ett', 'antal', 'kolleger', 'begärt,', 'håller', 'en', 'tyst', 'minut', 'för', 'offren', 'för', 'bl.a.', 'stormarna', 'i', 'de', 'länder', 'i', 'europeiska', 'unionen', 'som', 'drabbats.'], ['jag', 'ber', 'er', 'resa', 'er', 'för', 'en', 'tyst', 'minut.'], ['(parlamentet', 'höll', 'en', 'tyst', 'minut.)'], ['fru', 'talman!', 'det', 'gäller', 'en', 'ordningsfråga.'], ['ni', 'känner', 'till', 'från', 'media', 'att', 'det', 'skett', 'en', 'rad', 'bombexplosioner', 'och', 'mord', 'i', 'sri', 'lanka.'], ['en', 'av', 'de', 'personer', 'som', 'mycket', 'nyligen', 'mördades', 'i', 'sri', 'lanka', 'var', 'kumar', 'ponnambalam,', 'som', 'besökte', 'europaparlamentet', 'för', 'bara', 'några', 'månader', 'sedan.']]\n",
      "1862234\n",
      "1862234\n"
     ]
    }
   ],
   "source": [
    "#A2.1 Pre-process the text from both RDDs by doing the following: Lowercase the text + Tokenize the text (split on space)\n",
    "\n",
    "def lowercase_and_split(rdd_input):\n",
    "    \"\"\"Takes in a rdd and outputs all the values in second position in the tuple\n",
    "    lowercased and splited on space\"\"\"\n",
    "    return rdd_input.map(lambda w: w[1].lower().split(' '))\n",
    "\n",
    "# A.2.2 Inspect 10 entries from each of your RDDs to verify your pre-processing.\n",
    "rdd_en_lower_split = lowercase_and_split(rdd_en)\n",
    "rdd_sv_lower_split = lowercase_and_split(rdd_sv)\n",
    "\n",
    "print(rdd_en_lower_split.take(10)) #print 10 entries from English text\n",
    "print(rdd_sv_lower_split.take(10)) #print 10 entries from Swedish text\n",
    "\n",
    "# A.2.3 Verify that the line counts still match after the pre-processing\n",
    "print(rdd_en_lower_split.count())\n",
    "print(rdd_sv_lower_split.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "connected-terry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 3498375), ('of', 1659758), ('to', 1539760), ('and', 1288401), ('in', 1085993), ('that', 797516), ('a', 773522), ('is', 758050), ('for', 534242), ('we', 522849)]\n",
      "[('att', 1706293), ('och', 1344830), ('i', 1050774), ('det', 924866), ('som', 913276), ('för', 908680), ('av', 738068), ('är', 694381), ('en', 620310), ('vi', 539797)]\n"
     ]
    }
   ],
   "source": [
    "# A.3.1 Use Spark to compute the 10 most frequently according words in the English language corpus. Repeat for the other language.\n",
    "from operator import add\n",
    "\n",
    "#English text\n",
    "all_words_en = rdd_en_lower_split.flatMap(lambda w: w)\\\n",
    "    .map(lambda w: (w,1))\n",
    "\n",
    "word_counts_en = all_words_en.reduceByKey(add)\n",
    "print(word_counts_en.takeOrdered(10, key=lambda x: -x[1]))\n",
    "\n",
    "#Swedish text\n",
    "all_words_sv = rdd_sv_lower_split.flatMap(lambda w: w)\\\n",
    "    .map(lambda w: (w,1))\n",
    "\n",
    "word_counts_sv = all_words_sv.reduceByKey(add)\n",
    "print(word_counts_sv.takeOrdered(10, key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-fiber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.3.2 Verify that your results are reasonable.\n",
    "\n",
    "# Ans: Yes, the results are reasonable. If we look above at the top 10 most common words in both languanges we see that they are \n",
    "# very similar to each other and they are also what you would expect - a lot of prepositions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "funky-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.4.1\n",
    "#1. Key the lines by their line number\n",
    "en_1 = rdd_en_lower_split\n",
    "en_1 = en_1.zipWithIndex()\n",
    "\n",
    "sv_1 = rdd_sv_lower_split\n",
    "sv_1 = sv_1.zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "instant-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Swap the key and value - so that the line number is the key\n",
    "en_2 = en_1.map(lambda w: (w[1],w[0]))\n",
    "sv_2 = sv_1.map(lambda w: (w[1],w[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "plain-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Join on key\n",
    "joined_en_sv_3 = en_2.join(sv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "removed-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Filter to exclude line pairs that have an empty/missing “corresponding” sentence.\n",
    "joined_en_sv_4 = joined_en_sv_3.filter(lambda w:w[1][0]!=[''])\\\n",
    "                   .filter(lambda w:w[1][1]!=[''])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coated-small",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Filter to have only pairs of sentences with a small number of words per sentence (I use 4 words or less)\n",
    "joined_en_sv_5 = joined_en_sv_4.filter(lambda w:len(w[1][0])<5)\\\n",
    "                               .filter(lambda w:len(w[1][1])<5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "roman-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Filter to leave only pairs of sentences with the same number of words in each sentence\n",
    "joined_en_sv_6 = joined_en_sv_5.filter(lambda w:len(w[1][0])==len(w[1][1]))\n",
    "                               \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "regional-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 For each sentence pair, map so that you pair each (in order) word in the two sentences. We no longer need the line numbers. (hint: use python’s built in zip() function)\n",
    "#Step 1: drop line number\n",
    "#Step 2: zip corresponding words\n",
    "#Step 3: #return as tuple\n",
    "\n",
    "joined_en_sv_7 = joined_en_sv_6.map(lambda w:w[1])\\\n",
    "                               .map(lambda w:zip(w[0],w[1]))\\\n",
    "                               .map(lambda w:tuple(w))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceramic-necessity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('(applause)', '(applåder)'), 2546), (('closed.', 'avslutad.'), 2534), (('is', 'är'), 2380), (('.', '.'), 2082), (('is', 'debatten'), 1324), (('the', 'jag'), 1324), (('debate', 'förklarar'), 1317), (('the', 'debatten'), 1225), (('is', 'härmed'), 1215), (('debate', 'är'), 1187), (('(rule', '(artikel'), 893), (('that', 'det'), 852), (('written', 'skriftliga'), 847), (('\\xa0\\xa0', '\\xa0\\xa0'), 842), (('statements', 'förklaringar'), 801), (('we', 'vi'), 636), (('i', 'jag'), 629), (('this', 'detta'), 582), (('142)', '142)'), 557), (('it', 'det'), 515), (('applause', 'applåder'), 461), (('1.', '1.'), 438), (('2.', '2.'), 438), (('there', 'det'), 429), (('3.', '3.'), 405), (('why?', 'varför?'), 372), (('-', '-'), 367), (('are', 'är'), 364), (('this', 'det'), 361), (('are', 'finns'), 360)]\n"
     ]
    }
   ],
   "source": [
    "# 8. Use reduce to count the number of occurrences of the word-translation-pairs\n",
    "from operator import add\n",
    "\n",
    "joined_en_sv_8 = joined_en_sv_7.flatMap(lambda w: (w))\\\n",
    "                               .map(lambda w: (w,1))\n",
    "\n",
    "word_counts_joined_en_sv_8 = joined_en_sv_8.reduceByKey(add)\n",
    "print(word_counts_joined_en_sv_8.takeOrdered(30, key=lambda x: -x[1])) #print some of the most frequent occuring pairs of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "published-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: Do the translations seem resonable?\n",
    "\n",
    "#Answer:  Most of them makes sense. \"Applause\", \"closed\", \"is\", \"rule\" and \"written\" are some of the words that get correct translations. Some are wrong like ('is','debatten'). \n",
    "# Most likely due to the fact that in English the definite article (the) is used before a noun to indicate that the identity of the noun is known to the reader, while in Swedish \n",
    "# this is done by changing the ending of the word itself. \n",
    "# There are a few number characters and other wierd characters that one would preferrably filter out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "military-mayor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release the cores for another application!\n",
    "spark_context.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
