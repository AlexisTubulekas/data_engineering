{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ignored-april",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "great-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.113:7077\") \\\n",
    "        .appName(\"alexistubulekasA3_partA\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .config(\"spark.cores.max\",2)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electrical-benjamin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1862234"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A.1.1 Read the English transcripts with Spark, and count the number of lines.\n",
    "\n",
    "rdd_en = spark_context.newAPIHadoopFile(\n",
    "    'hdfs://192.168.2.113:9000/europarl/europarl-v7.sv-en.en',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text',\n",
    "    conf={'textinputformat.record.delimiter': '\\n'}\n",
    ")\\\n",
    ".cache() # Keep this RDD in memory!\n",
    "\n",
    "rdd_en.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "organizational-bronze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1862234"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A.1.2 Do the same with the other language (so that you have a separate lineage of RDDs for each).\n",
    "rdd_sv = spark_context.newAPIHadoopFile(\n",
    "    'hdfs://192.168.2.113:9000/europarl/europarl-v7.sv-en.sv',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text',\n",
    "    conf={'textinputformat.record.delimiter': '\\n'}\n",
    ")\\\n",
    ".cache() # Keep this RDD in memory!\n",
    "rdd_sv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.1.3 Verify that the line counts are the same for the two languages.\n",
    "\n",
    "# Ans: Yes they are the same as seen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "auburn-combine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A.1.4 Count the number of partitions.\n",
    "rdd_en.getNumPartitions()\n",
    "rdd_sv.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "honey-number",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Resumption of the session'), (26, 'I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.'), (234, \"Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\")]\n"
     ]
    }
   ],
   "source": [
    "rdd_en_take3 = rdd_en.take(3)\n",
    "print(rdd_en_take3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "future-scratch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['resumption', 'of', 'the', 'session'], ['i', 'declare', 'resumed', 'the', 'session', 'of', 'the', 'european', 'parliament', 'adjourned', 'on', 'friday', '17', 'december', '1999,', 'and', 'i', 'would', 'like', 'once', 'again', 'to', 'wish', 'you', 'a', 'happy', 'new', 'year', 'in', 'the', 'hope', 'that', 'you', 'enjoyed', 'a', 'pleasant', 'festive', 'period.'], ['although,', 'as', 'you', 'will', 'have', 'seen,', 'the', 'dreaded', \"'millennium\", \"bug'\", 'failed', 'to', 'materialise,', 'still', 'the', 'people', 'in', 'a', 'number', 'of', 'countries', 'suffered', 'a', 'series', 'of', 'natural', 'disasters', 'that', 'truly', 'were', 'dreadful.'], ['you', 'have', 'requested', 'a', 'debate', 'on', 'this', 'subject', 'in', 'the', 'course', 'of', 'the', 'next', 'few', 'days,', 'during', 'this', 'part-session.'], ['in', 'the', 'meantime,', 'i', 'should', 'like', 'to', 'observe', 'a', \"minute'\", 's', 'silence,', 'as', 'a', 'number', 'of', 'members', 'have', 'requested,', 'on', 'behalf', 'of', 'all', 'the', 'victims', 'concerned,', 'particularly', 'those', 'of', 'the', 'terrible', 'storms,', 'in', 'the', 'various', 'countries', 'of', 'the', 'european', 'union.'], ['please', 'rise,', 'then,', 'for', 'this', \"minute'\", 's', 'silence.'], ['(the', 'house', 'rose', 'and', 'observed', 'a', \"minute'\", 's', 'silence)'], ['madam', 'president,', 'on', 'a', 'point', 'of', 'order.'], ['you', 'will', 'be', 'aware', 'from', 'the', 'press', 'and', 'television', 'that', 'there', 'have', 'been', 'a', 'number', 'of', 'bomb', 'explosions', 'and', 'killings', 'in', 'sri', 'lanka.'], ['one', 'of', 'the', 'people', 'assassinated', 'very', 'recently', 'in', 'sri', 'lanka', 'was', 'mr', 'kumar', 'ponnambalam,', 'who', 'had', 'visited', 'the', 'european', 'parliament', 'just', 'a', 'few', 'months', 'ago.']]\n",
      "[['återupptagande', 'av', 'sessionen'], ['jag', 'förklarar', 'europaparlamentets', 'session', 'återupptagen', 'efter', 'avbrottet', 'den', '17', 'december.', 'jag', 'vill', 'på', 'nytt', 'önska', 'er', 'ett', 'gott', 'nytt', 'år', 'och', 'jag', 'hoppas', 'att', 'ni', 'haft', 'en', 'trevlig', 'semester.'], ['som', 'ni', 'kunnat', 'konstatera', 'ägde', '\"den', 'stora', 'år', '2000-buggen\"', 'aldrig', 'rum.', 'däremot', 'har', 'invånarna', 'i', 'ett', 'antal', 'av', 'våra', 'medlemsländer', 'drabbats', 'av', 'naturkatastrofer', 'som', 'verkligen', 'varit', 'förskräckliga.'], ['ni', 'har', 'begärt', 'en', 'debatt', 'i', 'ämnet', 'under', 'sammanträdesperiodens', 'kommande', 'dagar.'], ['till', 'dess', 'vill', 'jag', 'att', 'vi,', 'som', 'ett', 'antal', 'kolleger', 'begärt,', 'håller', 'en', 'tyst', 'minut', 'för', 'offren', 'för', 'bl.a.', 'stormarna', 'i', 'de', 'länder', 'i', 'europeiska', 'unionen', 'som', 'drabbats.'], ['jag', 'ber', 'er', 'resa', 'er', 'för', 'en', 'tyst', 'minut.'], ['(parlamentet', 'höll', 'en', 'tyst', 'minut.)'], ['fru', 'talman!', 'det', 'gäller', 'en', 'ordningsfråga.'], ['ni', 'känner', 'till', 'från', 'media', 'att', 'det', 'skett', 'en', 'rad', 'bombexplosioner', 'och', 'mord', 'i', 'sri', 'lanka.'], ['en', 'av', 'de', 'personer', 'som', 'mycket', 'nyligen', 'mördades', 'i', 'sri', 'lanka', 'var', 'kumar', 'ponnambalam,', 'som', 'besökte', 'europaparlamentet', 'för', 'bara', 'några', 'månader', 'sedan.']]\n",
      "1862234\n",
      "1862234\n"
     ]
    }
   ],
   "source": [
    "#A2.1 Pre-process the text from both RDDs by doing the following: Lowercase the text + Tokenize the text (split on space)\n",
    "\n",
    "def lowercase_and_split(rdd_input):\n",
    "    \"\"\"Takes in a rdd and outputs all the values in second position in the tuple\n",
    "    lowercased and splited on space\"\"\"\n",
    "    return rdd_input.map(lambda w: w[1].lower().split(' '))\n",
    "\n",
    "# A.2.2 Inspect 10 entries from each of your RDDs to verify your pre-processing.\n",
    "rdd_en_lower_split = lowercase_and_split(rdd_en)\n",
    "rdd_sv_lower_split = lowercase_and_split(rdd_sv)\n",
    "\n",
    "print(rdd_en_lower_split.take(10))\n",
    "print(rdd_sv_lower_split.take(10))\n",
    "\n",
    "# A.2.3 Verify that the line counts still match after the pre-processing\n",
    "print(rdd_en_lower_split.count())\n",
    "print(rdd_sv_lower_split.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "general-climate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 3498375), ('of', 1659758), ('to', 1539760), ('and', 1288401), ('in', 1085993), ('that', 797516), ('a', 773522), ('is', 758050), ('for', 534242), ('we', 522849)]\n",
      "[('att', 1706293), ('och', 1344830), ('i', 1050774), ('det', 924866), ('som', 913276), ('för', 908680), ('av', 738068), ('är', 694381), ('en', 620310), ('vi', 539797)]\n"
     ]
    }
   ],
   "source": [
    "# A.3.1 Use Spark to compute the 10 most frequently according words in the English language corpus. Repeat for the other language.\n",
    "from operator import add\n",
    "\n",
    "#English text\n",
    "all_words_en = rdd_en_lower_split.flatMap(lambda w: w)\\\n",
    "    .map(lambda w: (w,1))\n",
    "\n",
    "word_counts_en = all_words_en.reduceByKey(add)\n",
    "print(word_counts_en.takeOrdered(10, key=lambda x: -x[1]))\n",
    "\n",
    "#Swedish text\n",
    "all_words_sv = rdd_sv_lower_split.flatMap(lambda w: w)\\\n",
    "    .map(lambda w: (w,1))\n",
    "\n",
    "word_counts_sv = all_words_sv.reduceByKey(add)\n",
    "print(word_counts_sv.takeOrdered(10, key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.3.2 Verify that your results are reasonable.\n",
    "\n",
    "#Ans: Yes, the results are reasonable. If we look above at the top 10 most common words in both languanges we see that they are very similar to each other and they are\n",
    "# also what you would expect, a lot of prepositions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suitable-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.4.1 \n",
    "# Use this parallel corpus to mine some translations in the form of word pairs, for the two languages. Do this by pairing words found on short lines with \n",
    "# the same number of words respectively. We (incorrectly) assume the words stay in the same order when translated.\n",
    "\n",
    "#Follow this approach. Work with the pair of RDDs you created in question A.2. Hint: make a new pair of RDDs for each step, sv_1, en_1, sv_2, en_2, ...\n",
    "\n",
    "# 1. Key the lines by their line number (hint: ZipWithIndex()).\n",
    "# 2. Swap the key and value - so that the line number is the key.\n",
    "# 3. Join the two RDDs together according to the line number key, so you have pairs of matching lines.\n",
    "# 4. Filter to exclude line pairs that have an empty/missing “corresponding” sentence.\n",
    "# 5. Filter to leave only pairs of sentences with a small number of words per sentence, this should give a more reliable translation (you can experiment).\n",
    "# 6. Filter to leave only pairs of sentences with the same number of words in each sentence.\n",
    "# 7. For each sentence pair, map so that you pair each (in order) word in the two sentences. We no longer need the line numbers. \n",
    "# hint: use python’s built in zip() function\n",
    "# 8. Use reduce to count the number of occurrences of the word-translation-pairs.\n",
    "# 9. Print some of the most frequently occurring pairs of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "objective-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Key the lines by their line number\n",
    "en_1 = rdd_en_lower_split\n",
    "en_1 = en_1.zipWithIndex()\n",
    "\n",
    "sv_1 = rdd_sv_lower_split\n",
    "sv_1 = sv_1.zipWithIndex()\n",
    "#print(en_1.take(2))\n",
    "#print(sv_1.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intelligent-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Swap the key and value - so that the line number is the key\n",
    "en_2 = en_1.map(lambda w: (w[1],w[0]))\n",
    "sv_2 = sv_1.map(lambda w: (w[1],w[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "offshore-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Join on key\n",
    "joined_en_sv_3 = en_2.join(sv_2)\n",
    "#joined_en_sv.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "muslim-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Filter to exclude line pairs that have an empty/missing “corresponding” sentence.\n",
    "joined_en_sv_4 = joined_en_sv_3.filter(lambda w:w[1][0]!=[''])\\\n",
    "                   .filter(lambda w:w[1][1]!=[''])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "coastal-slave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(587725,\n",
       "  (['i', 'completely', 'agree.'], ['jag', 'håller', 'fullständigt', 'med.'])),\n",
       " (103675, (['.'], ['.']))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Filter to have only pairs of sentences with a small number of words per sentence (I use 4 words or less)\n",
    "joined_en_sv_5 = joined_en_sv_4.filter(lambda w:len(w[1][0])<5)\\\n",
    "                               .filter(lambda w:len(w[1][1])<5)\n",
    "\n",
    "#joined_en_sv_5.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eight-disorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(88670, (['.'], ['.'])), (277115, (['why?'], ['varför?']))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. Filter to leave only pairs of sentences with the same number of words in each sentence\n",
    "joined_en_sv_6 = joined_en_sv_5.filter(lambda w:len(w[1][0])==len(w[1][1]))\n",
    "                               \n",
    "\n",
    "joined_en_sv_6.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "copyrighted-jones",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('that', 'detta'),\n",
       "  ('was', 'vägrades'),\n",
       "  ('also', 'oss'),\n",
       "  ('refused.', 'likaså.')),\n",
       " (('the', 'jag'),\n",
       "  ('debate', 'förklarar'),\n",
       "  ('is', 'debatten'),\n",
       "  ('closed.', 'avslutad.')),\n",
       " (('i', 'jag'), ('doubt', 'betvivlar'), ('it.', 'det!')),\n",
       " (('the', 'jag'),\n",
       "  ('debate', 'förklarar'),\n",
       "  ('is', 'debatten'),\n",
       "  ('closed.', 'avslutad.'))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7 For each sentence pair, map so that you pair each (in order) word in the two sentences. We no longer need the line numbers. (hint: use python’s built in zip() function)\n",
    "\n",
    "joined_en_sv_7 = joined_en_sv_6.map(lambda w:w[1])\\ #drop line number\n",
    "                               .map(lambda w:zip(w[0],w[1]))\\ #zip corresponding words\n",
    "                               .map(lambda w:tuple(w)) #return as tuple\n",
    "joined_en_sv_7.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "emerging-hygiene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('(applause)', '(applåder)'), 2546), (('closed.', 'avslutad.'), 2534), (('is', 'är'), 2380), (('.', '.'), 2082), (('is', 'debatten'), 1324), (('the', 'jag'), 1324), (('debate', 'förklarar'), 1317), (('the', 'debatten'), 1225), (('is', 'härmed'), 1215), (('debate', 'är'), 1187), (('(rule', '(artikel'), 893), (('that', 'det'), 852), (('written', 'skriftliga'), 847), (('\\xa0\\xa0', '\\xa0\\xa0'), 842), (('statements', 'förklaringar'), 801), (('we', 'vi'), 636), (('i', 'jag'), 629), (('this', 'detta'), 582), (('142)', '142)'), 557), (('it', 'det'), 515), (('applause', 'applåder'), 461), (('2.', '2.'), 438), (('1.', '1.'), 438), (('there', 'det'), 429), (('3.', '3.'), 405), (('why?', 'varför?'), 372), (('-', '-'), 367), (('are', 'är'), 364), (('this', 'det'), 361), (('are', 'finns'), 360)]\n"
     ]
    }
   ],
   "source": [
    "# 8. Use reduce to count the number of occurrences of the word-translation-pairs\n",
    "from operator import add\n",
    "\n",
    "joined_en_sv_8 = joined_en_sv_7.flatMap(lambda w: (w))\\\n",
    "                               .map(lambda w: (w,1))\n",
    "\n",
    "word_counts_joined_en_sv_8 = joined_en_sv_8.reduceByKey(add)\n",
    "print(word_counts_joined_en_sv_8.takeOrdered(30, key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stylish-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release the cores for another application!\n",
    "spark_context.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
