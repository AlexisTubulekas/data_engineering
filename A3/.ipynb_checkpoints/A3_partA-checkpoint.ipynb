{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "consistent-simpson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cutting-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.113:7077\") \\\n",
    "        .appName(\"alexistubulekasA3_partA\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .config(\"spark.cores.max\",6)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "preceding-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sv = spark_session.sparkContext.textFile('hdfs://192.168.2.113:9000/europarl/europarl-v7.sv-en.sv').cache()\n",
    "#en = spark_session.sparkContext.textFile('hdfs://192.168.2.113:9000/europarl/europarl-v7.sv-en.en').cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "christian-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# New API        \n",
    "#\n",
    "#spark_session = SparkSession\\\n",
    "#        .builder\\\n",
    "#        .master(\"spark://192.168.2.113:7077\")  \\\n",
    "#        .appName(\"alexistubulekasA3_partA\")\\\n",
    "#        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "#        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "#        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "#        .config(\"spark.executor.cores\",2)\\\n",
    "#        .config(\"spark.cores.max\",2)\\\n",
    "#        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acoustic-circuit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1862234"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_en = spark_context.newAPIHadoopFile(\n",
    "    'hdfs://192.168.2.113:9000/europarl/europarl-v7.sv-en.en',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text',\n",
    "    conf={'textinputformat.record.delimiter': '\\n'}\n",
    ")\\\n",
    ".cache() # Keep this RDD in memory!\n",
    "\n",
    "#A1.1\n",
    "rdd_en.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "anticipated-heather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A1.4\n",
    "rdd_en.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "relevant-blanket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1862234"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_sv = spark_context.newAPIHadoopFile(\n",
    "    'hdfs://192.168.2.113:9000/europarl/europarl-v7.sv-en.sv',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text',\n",
    "    conf={'textinputformat.record.delimiter': '\\n'}\n",
    ")\\\n",
    ".cache() # Keep this RDD in memory!\n",
    "\n",
    "#A1.2\n",
    "rdd_sv.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ongoing-chaos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A1.4\n",
    "rdd_sv.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "three-ribbon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Resumption of the session'), (26, 'I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.'), (234, \"Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\")]\n"
     ]
    }
   ],
   "source": [
    "rdd_en_take3 = rdd_en.take(3)\n",
    "print(rdd_en_take3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "published-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A2.1\n",
    "def lowercase_and_split(rdd_input):\n",
    "    \"\"\"Takes in a rdd and outputs all the values in second position in the tuple\n",
    "    lowercased and splited on space\"\"\"\n",
    "    return rdd_input.map(lambda w: w[1].lower().split(' '))\n",
    "\n",
    "# A.2.2 Inspect 10 entries from each of your RDDs to verify your pre-processing.\n",
    "rdd_en_lower_split = lowercase_and_split(rdd_en)\n",
    "rdd_sv_lower_split = lowercase_and_split(rdd_sv)\n",
    "\n",
    "#print(rdd_en_lower_split.take(10))\n",
    "#print(rdd_sv_lower_split.take(10))\n",
    "\n",
    "# A.2.3 Verify that the line counts still match after the pre-processing\n",
    "#print(rdd_en_lower_split.count())\n",
    "#print(rdd_sv_lower_split.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cordless-liechtenstein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 3498375), ('of', 1659758), ('to', 1539760), ('and', 1288401), ('in', 1085993), ('that', 797516), ('a', 773522), ('is', 758050), ('for', 534242), ('we', 522849)]\n",
      "[('att', 1706293), ('och', 1344830), ('i', 1050774), ('det', 924866), ('som', 913276), ('för', 908680), ('av', 738068), ('är', 694381), ('en', 620310), ('vi', 539797)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# A.3.1 Use Spark to compute the 10 most frequently according words in the English language corpus. Repeat for the other language.\n",
    "# A.3.2 Verify that your results are reasonable.\n",
    "from operator import add\n",
    "\n",
    "#English text\n",
    "all_words_en = rdd_en_lower_split.flatMap(lambda w: w)\\\n",
    "    .map(lambda w: (w,1))\n",
    "\n",
    "word_counts_en = all_words_en.reduceByKey(add)\n",
    "print(word_counts_en.takeOrdered(10, key=lambda x: -x[1]))\n",
    "\n",
    "#Swedish text\n",
    "all_words_sv = rdd_sv_lower_split.flatMap(lambda w: w)\\\n",
    "    .map(lambda w: (w,1))\n",
    "\n",
    "word_counts_sv = all_words_sv.reduceByKey(add)\n",
    "print(word_counts_sv.takeOrdered(10, key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.4.1 \n",
    "# Use this parallel corpus to mine some translations in the form of word pairs, for the two languages. Do this by pairing words found on short lines with \n",
    "# the same number of words respectively. We (incorrectly) assume the words stay in the same order when translated.\n",
    "\n",
    "#Follow this approach. Work with the pair of RDDs you created in question A.2. Hint: make a new pair of RDDs for each step, sv_1, en_1, sv_2, en_2, ...\n",
    "\n",
    "# 1. Key the lines by their line number (hint: ZipWithIndex()).\n",
    "# 2. Swap the key and value - so that the line number is the key.\n",
    "# 3. Join the two RDDs together according to the line number key, so you have pairs of matching lines.\n",
    "# 4. Filter to exclude line pairs that have an empty/missing “corresponding” sentence.\n",
    "# 5. Filter to leave only pairs of sentences with a small number of words per sentence, this should give a more reliable translation (you can experiment).\n",
    "# 6. Filter to leave only pairs of sentences with the same number of words in each sentence.\n",
    "# 7. For each sentence pair, map so that you pair each (in order) word in the two sentences. We no longer need the line numbers. \n",
    "# hint: use python’s built in zip() function\n",
    "# 8. Use reduce to count the number of occurrences of the word-translation-pairs.\n",
    "# 9. Print some of the most frequently occurring pairs of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dying-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Key the lines by their line number\n",
    "en_1 = rdd_en_lower_split\n",
    "en_1 = en_1.zipWithIndex()\n",
    "\n",
    "sv_1 = rdd_sv_lower_split\n",
    "sv_1 = sv_1.zipWithIndex()\n",
    "#print(en_1.take(2))\n",
    "#print(sv_1.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "peripheral-separation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1, 2, 10)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "occasional-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Swap the key and value - so that the line number is the key\n",
    "en_2 = en_1.map(lambda w: (w[1],w[0]))\n",
    "sv_2 = sv_1.map(lambda w: (w[1],w[0]))\n",
    "\n",
    "\n",
    "#Working with sublists to make computation easier\n",
    "list_range = range(5)\n",
    "en_2_sub = en_2.filter(lambda w:w[0] in list_range)\n",
    "sv_2_sub = sv_2.filter(lambda w:w[0] in list_range)\n",
    "\n",
    "join_sub = en_2_sub.join(sv_2_sub)\n",
    "join_sub = join_sub.filter(lambda w:w[1][0]!=[])\\\n",
    "                   .filter(lambda w:w[1][1]!=[])\n",
    "\n",
    "#join_sub.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-table",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "supposed-difference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Join on key\n",
    "joined_en_sv_3 = en_2.join(sv_2)\n",
    "#joined_en_sv.take(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "encouraging-emission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(565,\n",
       "  (['i',\n",
       "    'mean',\n",
       "    'the',\n",
       "    'attitude',\n",
       "    'where',\n",
       "    'a',\n",
       "    'person',\n",
       "    'wants',\n",
       "    'to',\n",
       "    'get',\n",
       "    'on',\n",
       "    'in',\n",
       "    'life,',\n",
       "    'whether',\n",
       "    'he',\n",
       "    'or',\n",
       "    'she',\n",
       "    'is',\n",
       "    'an',\n",
       "    'employee,',\n",
       "    'the',\n",
       "    'owner',\n",
       "    'of',\n",
       "    'a',\n",
       "    'business',\n",
       "    'or',\n",
       "    'an',\n",
       "    'official.'],\n",
       "   ['jag',\n",
       "    'menar',\n",
       "    'den',\n",
       "    'inställningen',\n",
       "    'att',\n",
       "    'en',\n",
       "    'människa',\n",
       "    'vill',\n",
       "    'gå',\n",
       "    'framåt',\n",
       "    'i',\n",
       "    'sitt',\n",
       "    'liv',\n",
       "    'oavsett',\n",
       "    'om',\n",
       "    'hon',\n",
       "    'är',\n",
       "    'arbetare,',\n",
       "    'företagare',\n",
       "    'eller',\n",
       "    'tjänsteman.'])),\n",
       " (695,\n",
       "  (['this',\n",
       "    'being',\n",
       "    'the',\n",
       "    'case,',\n",
       "    'there',\n",
       "    'are',\n",
       "    'considerable',\n",
       "    'disparities',\n",
       "    'between',\n",
       "    'states,',\n",
       "    'which',\n",
       "    'may',\n",
       "    'be',\n",
       "    'measured',\n",
       "    'in',\n",
       "    'various',\n",
       "    'ways,',\n",
       "    'such',\n",
       "    'as,',\n",
       "    'for',\n",
       "    'example,',\n",
       "    'as',\n",
       "    'a',\n",
       "    'percentage',\n",
       "    'of',\n",
       "    'added',\n",
       "    'value',\n",
       "    'and',\n",
       "    'per',\n",
       "    'wage',\n",
       "    'earner.'],\n",
       "   ['samtidigt',\n",
       "    'är',\n",
       "    'skillnaderna',\n",
       "    'mellan',\n",
       "    'staterna',\n",
       "    'avsevärda',\n",
       "    'och',\n",
       "    'kan',\n",
       "    'bedömas',\n",
       "    'på',\n",
       "    'olika',\n",
       "    'sätt,',\n",
       "    'bl.a.',\n",
       "    'i',\n",
       "    'procent',\n",
       "    'av',\n",
       "    'mervärdet',\n",
       "    'och',\n",
       "    'per',\n",
       "    'löntagare.'])),\n",
       " (1235,\n",
       "  (['i',\n",
       "    'share',\n",
       "    'that',\n",
       "    'concern',\n",
       "    'and',\n",
       "    'i',\n",
       "    'believe',\n",
       "    'that',\n",
       "    'this',\n",
       "    'issue',\n",
       "    'should',\n",
       "    'be',\n",
       "    'addressed.'],\n",
       "   ['jag',\n",
       "    'delar',\n",
       "    'hennes',\n",
       "    'oro',\n",
       "    'och',\n",
       "    'anser',\n",
       "    'att',\n",
       "    'den',\n",
       "    'saken',\n",
       "    'bör',\n",
       "    'undersökas.']))]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_en_sv_3.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "meaningful-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Filter to exclude line pairs that have an empty/missing “corresponding” sentence.\n",
    "joined_en_sv_4 = joined_en_sv_3.filter(lambda w:w[1][0]!=[''])\\\n",
    "                   .filter(lambda w:w[1][1]!=[''])\n",
    "\n",
    "#joined_en_sv_4.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "documentary-sucking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(982955, (['there', 'are', 'solutions.'], ['det', 'finns', 'lösningar.'])),\n",
       " (1381225, (['6.'], ['6.'])),\n",
       " (1425665, (['(applause)'], ['(applåder)'])),\n",
       " (1550685, (['probably', 'not!'], ['troligtvis', 'inte!'])),\n",
       " (1036910,\n",
       "  (['voting', 'time', '(continuation)'], ['omröstning', '(fortsättning)'])),\n",
       " (1051495, (['10.'], ['10.'])),\n",
       " (1157290, (['10.'], ['10.'])),\n",
       " (1176380, (['(applause)'], ['(applåder)'])),\n",
       " (1176685, (['honduras', '(debate)'], ['honduras', '(debatt)'])),\n",
       " (1253985, (['thank', 'you', 'all.'], ['tack', 'alla.']))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Filter to have only pairs of sentences with a small number of words per sentence (less than 4)\n",
    "joined_en_sv_5 = joined_en_sv_4.filter(lambda w:len(w[1][0])<4)\\\n",
    "                               .filter(lambda w:len(w[1][1])<4)\n",
    "\n",
    "joined_en_sv_5.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "chubby-tolerance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(210510, (['vote', '(continuation)'], ['omröstning', '(fortsättning)'])),\n",
       " (667265, (['\\xa0\\xa0', '.'], ['\\xa0\\xa0', '.'])),\n",
       " (860085, (['(applause)'], ['(applåder)'])),\n",
       " (644370, (['arms', 'are', 'dangerous.'], ['vapen', 'är', 'farliga.'])),\n",
       " (873825, (['(applause)'], ['(applåder)'])),\n",
       " (710235, (['\\xa0\\xa0', '.'], ['\\xa0\\xa0', '.'])),\n",
       " (891970, (['(applause)'], ['(applåder)'])),\n",
       " (226235, (['monitoring', 'of', 'bse'], ['övervakning', 'av', 'bse-krisen'])),\n",
       " (389585, (['.'], ['.'])),\n",
       " (400350, (['.'], ['.']))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. Filter to leave only pairs of sentences with the same number of words in each sentence\n",
    "joined_en_sv_6 = joined_en_sv_5.filter(lambda w:len(w[1][0])==len(w[1][1]))\n",
    "                               \n",
    "\n",
    "joined_en_sv_6.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "enabling-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release the cores for another application!\n",
    "spark_context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-violin",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
