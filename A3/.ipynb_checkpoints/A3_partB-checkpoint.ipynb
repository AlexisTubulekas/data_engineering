{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "vietnamese-death",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "parliamentary-hearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.113:7077\") \\\n",
    "        .appName(\"alexistubulekasA3_partB\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .config(\"spark.cores.max\",2)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "complicated-victory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+------------------+-----+------+--------------+---------------------+-----------+---------+---------+\n",
      "|Ticket number|         Issue Date|Issue time|Meter Id|Marked Time|RP State Plate|Plate Expiry Date| VIN|Make|Body Style|Color|          Location|Route|Agency|Violation code|Violation Description|Fine amount| Latitude|Longitude|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+------------------+-----+------+--------------+---------------------+-----------+---------+---------+\n",
      "|   1103341116|2015-12-21T00:00:00|      1251|    null|       null|            CA|           200304|null|HOND|        PA|   GY|   13147 WELBY WAY|01521|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|\n",
      "|   1103700150|2015-12-21T00:00:00|      1435|    null|       null|            CA|           201512|null| GMC|        VN|   WH|     525 S MAIN ST| 1C51|     1|        4000A1|   NO EVIDENCE OF REG|         50|    99999|    99999|\n",
      "|   1104803000|2015-12-21T00:00:00|      2055|    null|       null|            CA|           201503|null|NISS|        PA|   BK|     200 WORLD WAY|  2R2|     2|          8939|           WHITE CURB|         58|6439997.9|1802686.4|\n",
      "|   1104820732|2015-12-26T00:00:00|      1515|    null|       null|            CA|             null|null|ACUR|        PA|   WH|     100 WORLD WAY| 2F11|     2|           000|               17104h|       null|6440041.1|1802686.2|\n",
      "|   1105461453|2015-09-15T00:00:00|       115|    null|       null|            CA|           200316|null|CHEV|        PA|   BK|GEORGIA ST/OLYMPIC|1FB70|     1|         8069A| NO STOPPING/STANDING|         93|    99999|    99999|\n",
      "+-------------+-------------------+----------+--------+-----------+--------------+-----------------+----+----+----------+-----+------------------+-----+------+--------------+---------------------+-----------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.1 Load the CSV file from HDFS, and call show() to verify the data is loaded correctly\n",
    "data_frame = spark_session.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv('hdfs://192.168.2.113:9000/parking-citations.csv')\\\n",
    "    .cache()\n",
    "\n",
    "data_frame.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "necessary-collins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticket number: string (nullable = true)\n",
      " |-- Issue Date: string (nullable = true)\n",
      " |-- Issue time: string (nullable = true)\n",
      " |-- Meter Id: string (nullable = true)\n",
      " |-- Marked Time: string (nullable = true)\n",
      " |-- RP State Plate: string (nullable = true)\n",
      " |-- Plate Expiry Date: string (nullable = true)\n",
      " |-- VIN: string (nullable = true)\n",
      " |-- Make: string (nullable = true)\n",
      " |-- Body Style: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Route: string (nullable = true)\n",
      " |-- Agency: string (nullable = true)\n",
      " |-- Violation code: string (nullable = true)\n",
      " |-- Violation Description: string (nullable = true)\n",
      " |-- Fine amount: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.2 Print the schema for the DataFrame.\n",
    "data_frame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "lightweight-arena",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9257460"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B.3 Count the number of rows in the CSV file\n",
    "data_frame.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "nominated-proportion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B.4 Count the number of partitions in the underlying RDD.\n",
    "data_frame.rdd.getNumPartitions() #get num partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fleet-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B.5 Drop the columns VIN, Latitude and Longitude.\n",
    "data_frame = data_frame.drop('VIN','Latitude','Longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "educated-structure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|summary|Fine amount|\n",
      "+-------+-----------+\n",
      "|    max|      505.0|\n",
      "+-------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.6 Find the maximum fine amount. \n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "col_name = \"Fine amount\"\n",
    "data_frame = data_frame.withColumn(col_name, col(col_name).cast('float')) #recast fine amount column\n",
    "data_frame.select('Fine amount').summary('max').show() #show summary inc. max fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "incident-tribune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# B.6 How many fines have this amount?\n",
    "max_fine_df = data_frame.filter(data_frame['Fine amount'] == 505.0)\n",
    "max_fine_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "published-spank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+\n",
      "|Make|  count|\n",
      "+----+-------+\n",
      "|TOYT|1531949|\n",
      "|HOND|1043276|\n",
      "|FORD| 807498|\n",
      "|NISS| 662097|\n",
      "|CHEV| 631413|\n",
      "| BMW| 422916|\n",
      "|MERZ| 376830|\n",
      "|VOLK| 316002|\n",
      "|HYUN| 285286|\n",
      "|DODG| 271590|\n",
      "|LEXS| 263269|\n",
      "| KIA| 217795|\n",
      "|JEEP| 214965|\n",
      "|AUDI| 179718|\n",
      "|MAZD| 169811|\n",
      "|OTHR| 154376|\n",
      "| GMC| 132788|\n",
      "|INFI| 120340|\n",
      "|CHRY| 120317|\n",
      "|ACUR| 111265|\n",
      "+----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.7 Show the top 20 most frequent vehicle makes, and their frequencies.\n",
    "data_frame.groupby(\"Make\").count().sort(col(\"count\").desc()).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "legendary-transaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|Color|color long|\n",
      "+-----+----------+\n",
      "|   GY|      Gray|\n",
      "|   WH|     White|\n",
      "|   BK|     Black|\n",
      "|   WH|     White|\n",
      "|   BK|     Black|\n",
      "|   GY|      Gray|\n",
      "|   BL|      Blue|\n",
      "|   BK|     Black|\n",
      "|   BR|     Brown|\n",
      "|   SI|    Silver|\n",
      "|   WH|     White|\n",
      "|   GO|      Gold|\n",
      "|   BK|     Black|\n",
      "|   BK|     Black|\n",
      "|   BK|     Black|\n",
      "|   BK|     Black|\n",
      "|   WH|     White|\n",
      "| null|      null|\n",
      "|   BK|     Black|\n",
      "|   BK|     Black|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.8 Let’s expand some abbreviations in the color column. Create a User Defined Function to create a new column, ‘color long’, \n",
    "# mapping the original colors to their corresponding values in the dictionary below. If there is no key matching the original color, use the original color.\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "#step 1, create a python function\n",
    "COLORS = {\n",
    "'AL':'Aluminum', 'AM':'Amber', 'BG':'Beige', 'BK':'Black',\n",
    "'BL':'Blue', 'BN':'Brown', 'BR':'Brown', 'BZ':'Bronze',\n",
    "'CH':'Charcoal', 'DK':'Dark', 'GD':'Gold', 'GO':'Gold',\n",
    "'GN':'Green', 'GY':'Gray', 'GT':'Granite', 'IV':'Ivory',\n",
    "'LT':'Light', 'OL':'Olive', 'OR':'Orange', 'MR':'Maroon',\n",
    "'PK':'Pink', 'RD':'Red', 'RE':'Red', 'SI':'Silver', 'SL':'Silver',\n",
    "'SM':'Smoke', 'TN':'Tan', 'VT':'Violet', 'WT':'White',\n",
    "'WH':'White', 'YL':'Yellow', 'YE':'Yellow', 'UN':'Unknown'\n",
    "}\n",
    "\n",
    "def Color_to_Color_Long(abbreviation):\n",
    "    \n",
    "    if COLORS.get(abbreviation):\n",
    "        return COLORS.get(abbreviation)\n",
    "    else:\n",
    "        return abbreviation\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "# User-defined function. Input type is a string.\n",
    "udf_Color_to_Color_Long = udf(Color_to_Color_Long, StringType())\n",
    "\n",
    "data_frame_with_color_long = data_frame.withColumn(\"color long\", udf_Color_to_Color_Long(\"Color\"))\n",
    "\n",
    "data_frame_with_color_long.select('Color','color long').show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "defined-civilian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|color long| count|\n",
      "+----------+------+\n",
      "|      Gray|346822|\n",
      "+----------+------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# B.9 Using this new column, what’s the most frequent colour value for Toyotas (TOYT)?\n",
    "\n",
    "data_frame_with_color_long.filter(data_frame_with_color_long['Make'] == 'TOYT').groupby('color long').count().sort(col(\"count\").desc()).show(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "unlike-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release the cores for another application!\n",
    "spark_context.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
